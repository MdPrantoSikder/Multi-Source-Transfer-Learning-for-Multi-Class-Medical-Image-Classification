{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318940e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.applications import ResNet50, VGG16\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from utils.preprocessing import load_and_preprocess_images  # custom function\n",
    "\n",
    "# ==== Google Drive Dataset Path ====\n",
    "BASE_DIR = \"/content/drive/MyDrive/projects/v\"\n",
    "DATASET_DIR = os.path.join(BASE_DIR, \"dataset\")\n",
    "\n",
    "SOURCE1_DIR = os.path.join(DATASET_DIR, \"source1_lung_dataset\")\n",
    "SOURCE2_DIR = os.path.join(DATASET_DIR, \"source2_lung_dataset\")\n",
    "\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "LOGS_DIR = os.path.join(BASE_DIR, \"outputs/training_logs\")\n",
    "REPORTS_DIR = os.path.join(BASE_DIR, \"outputs/classification_reports\")\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "\n",
    "# ==== Load Data ====\n",
    "print(\"[INFO] Loading datasets from Google Drive...\")\n",
    "X1, y1 = load_and_preprocess_images(SOURCE1_DIR)\n",
    "X2, y2 = load_and_preprocess_images(SOURCE2_DIR)\n",
    "\n",
    "# Merge datasets\n",
    "X = np.concatenate([X1, X2], axis=0)\n",
    "y = np.concatenate([y1, y2], axis=0)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ==== Model Builder ====\n",
    "def build_model(base_model):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    predictions = Dense(len(np.unique(y)), activation=\"softmax\")(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "# ==== Train ResNet50 ====\n",
    "print(\"[INFO] Training ResNet50...\")\n",
    "resnet_base = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "resnet_model = build_model(resnet_base)\n",
    "\n",
    "resnet_model.compile(optimizer=Adam(1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "csv_logger_resnet = CSVLogger(os.path.join(LOGS_DIR, \"resnet50_training.log\"))\n",
    "checkpoint_resnet = ModelCheckpoint(os.path.join(MODELS_DIR, \"resnet50_model.h5\"), save_best_only=True, monitor=\"val_accuracy\", mode=\"max\")\n",
    "\n",
    "resnet_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[csv_logger_resnet, checkpoint_resnet]\n",
    ")\n",
    "\n",
    "# ==== Train VGG16 ====\n",
    "print(\"[INFO] Training VGG16...\")\n",
    "vgg_base = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "vgg_model = build_model(vgg_base)\n",
    "\n",
    "vgg_model.compile(optimizer=Adam(1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "csv_logger_vgg = CSVLogger(os.path.join(LOGS_DIR, \"vgg16_training.log\"))\n",
    "checkpoint_vgg = ModelCheckpoint(os.path.join(MODELS_DIR, \"vgg16_model.h5\"), save_best_only=True, monitor=\"val_accuracy\", mode=\"max\")\n",
    "\n",
    "vgg_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[csv_logger_vgg, checkpoint_vgg]\n",
    ")\n",
    "\n",
    "# ==== Ensemble Model ====\n",
    "print(\"[INFO] Building Ensemble Model...\")\n",
    "resnet_trained = load_model(os.path.join(MODELS_DIR, \"resnet50_model.h5\"))\n",
    "vgg_trained = load_model(os.path.join(MODELS_DIR, \"vgg16_model.h5\"))\n",
    "\n",
    "# Remove softmax layers\n",
    "resnet_feat = Model(inputs=resnet_trained.input, outputs=resnet_trained.layers[-2].output)\n",
    "vgg_feat = Model(inputs=vgg_trained.input, outputs=vgg_trained.layers[-2].output)\n",
    "\n",
    "input_layer = Input(shape=(224, 224, 3))\n",
    "resnet_output = resnet_feat(input_layer)\n",
    "vgg_output = vgg_feat(input_layer)\n",
    "\n",
    "merged = Concatenate()([resnet_output, vgg_output])\n",
    "final_output = Dense(len(np.unique(y)), activation=\"softmax\")(merged)\n",
    "ensemble_model = Model(inputs=input_layer, outputs=final_output)\n",
    "\n",
    "ensemble_model.compile(optimizer=Adam(1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "csv_logger_ens = CSVLogger(os.path.join(LOGS_DIR, \"ensemble_training.log\"))\n",
    "checkpoint_ens = ModelCheckpoint(os.path.join(MODELS_DIR, \"final_ensemble_model.h5\"), save_best_only=True, monitor=\"val_accuracy\", mode=\"max\")\n",
    "\n",
    "ensemble_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[csv_logger_ens, checkpoint_ens]\n",
    ")\n",
    "\n",
    "# ==== Evaluation ====\n",
    "print(\"[INFO] Evaluating Models...\")\n",
    "for model_name, model_path in [(\"ResNet50\", \"resnet50_model.h5\"), (\"VGG16\", \"vgg16_model.h5\"), (\"Ensemble\", \"final_ensemble_model.h5\")]:\n",
    "    model = load_model(os.path.join(MODELS_DIR, model_path))\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    report = classification_report(y_test, y_pred, target_names=[str(c) for c in np.unique(y)])\n",
    "    with open(os.path.join(REPORTS_DIR, f\"{model_name}_report.txt\"), \"w\") as f:\n",
    "        f.write(report)\n",
    "    print(f\"\\n===== {model_name} Report =====\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
